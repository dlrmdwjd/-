# 3-2. 선형 회귀

> 혼공머신이 전에 만든 모델의 **문제점** 
→ 새로운 샘플이 훈련 세트의 범위를 벗어나면 엉뚱한 값을 예측할 수 있다.
> 

### 〰️ 선형 회귀 (linear regression)

널리 사용되는 대표적인 회귀 알고리즘

특성과 타깃 사이의 관계를 가장 잘 나타내는 **선형 방정식**을 찾는다. 특성이 하나면 직선 방정식이 된다.

선형 회귀가 찾은 특성과 타깃 사이의 관계는 선형 방정식의 **계수** 또는 **가중치**에 저장된다. 머신러닝에서 종종 가중치는 방정식의 기울기와 절편을 모두 의미하는 경우가 많다. 

$$
y = ax + b
$$

예시의 경우 x는 농어의 길이, y는 농어의 무게를 의미한다. 선형 회귀가 데이터에 가장 잘 맞는 a와 b 값을 찾는다. 

- **`LinearRegression`** : 사이킷런의 선형 회귀 알고리즘 클래스, 선형 회귀/다항 회귀/다중 회귀를 지원한다.
    - **`coef_`** : 기울기, 계수(coefficient) 또는 가중치(weight)라고 부른다.
    - **`intercept_`** : 절편
        - `fit_intercept` 매개변수를 False로 지정하면 절편을 학습하지 않는다.
    - 머신러닝 알고리즘이 찾은 값이라는 의미로 **모델 파라미터**라고 부른다. → **모델 기반 학습**

** 사례 기반 학습 : 모델 파라미터 없이, 훈련 세트만으로 훈련하는 경우

### 👐 다항 회귀 (polynomial regression)

**다항식**을 사용한 선형 회귀

다항식을 사용하여 특성과 타깃 사이의 관계를 나타낸다. 이 함수는 비선형일 수 있지만 여전히 선형회귀로 표현할 수 있다. 

- **➕ [추가 조사] 다중 회귀, 다항 회귀**
    
    https://herjh0405.tistory.com/70