# 5-1. 결정 트리

**[와인 분류하기]**

특성 : 알코올 도수, 당도, pH

타깃 : 레드와인(0), 화이트와인(1) → 이진 분류

**** 데이터에서 누락된 값이 있으면?**

데이터를 버리거나 평균값으로 채운 후 사용. 어떤 방식이 최선인지는 미리 알기 어려우며, 두 가지 모두 시도해보는 것이 좋다. 

### 🌳 결정 트리 (Decision Tree)

예/아니오에 대한 질문을 이어나가면서 정답을 찾아 학습하는 알고리즘.

비교적 예측 과정을 이해하기 쉽고 성능도 뛰어나다. (설명하기 쉬운 모델)

결정 트리는 위에서부터 아래로 거꾸로 자라난다. 

맨 위의 노드(node)를 **루트 노드(root node)**라 부르고, 맨 아래 끝에 달린 노드를 **리프 노드(leaf node)**라고 한다. 

- **노드** : 결정 트리를 구성하는 핵심 요소. 훈련 데이터의 특성에 대한 테스트를 표현한다. 예를 들어, 현재 샘플의 당도가 -0.239보다 작거나 같은지 테스트.
- **가지(branch)** : 테스트의 결과(True, False)를 나타낸다. 일반적으로 하나의 노드는 2개의 가지를 가집니다.

**노드 구성 요소**

- 테스트 조건 (예 : sugar ≤ -0.239)
- 불순도 (gini)
- 총 샘플 수 (samples)
- 클래스별 샘플 수 (value)

**결정 트리의 예측 방법**

리프 노드에서 가장 많은 클래스가 예측 클래스가 된다. 

**특성 중요도**

결정 트리에 사용된 특성이 불순도를 감소하는 데에 기여한 정도를 나타내는 값.

각 노드의 정보 이득과 전체 샘플에 대한 비율을 곱한 후 특성별로 더하여 계산. 

결정 트리의 특성 중요도를 특성 선택에 활용할 수 있다. (결정 트리의 큰 장점!)

** 결정 트리에서 샘플을 어떤 클래스 비율로 나누는지 계산할 때 특성값의 스케일이 계산에 영향을 미치지 않으므로, **결정 트리 알고리즘에서는 표준화 전처리를 할 필요가 없다**. (큰 장점!)

### 🧞 불순도

결정 트리가 최적의 질문을 찾기 위한 기준

**지니 불순도 (Gini impurity)**

$$
지니 불순도 = 1 - (음성 클래스 비율^2 + 양성 클래스 비율^2)
$$

결정 트리 모델은 부모 노드(parent node)와 자식 노드(child node)의 불순도 차이가 가능한 크도록 트리를 성장시킨다. 

**정보 이득 (information gain)**

부모와 자식 노드 사이의 불순도 차이

- 계산 방법 : 자식 노드의 불순도를 샘플 개수에 비례하여 모두 더하고, 부모 노드의 불순도에서 뺀다.

$$
부모의 불순도 - (왼쪽 노드 샘플 수 / 부모의 샘플 수) * 왼쪽 노드 불순도 - (오른쪽 노드 샘플 수 / 부모의 샘플 수) * 오른쪽 노드 불순도
$$

**엔트로피 불순도 (entropy impurity)**

$$
-음성 클래스 비율 * log_2(음성 클래스 비율) - 양성 클래스 비율 * log_2(양성 클래스 비율)
$$

> 즉, 결정 트리는 **불순도 기준을 사용해 정보 이득이 최대가 되도록 노드를 분할**한다. 노드를 순수하게 나눌수록 정보 이득이 커진다. 새로운 샘플에 대해 예측할 때에는 노드의 질문에 따라 트리를 이동한다. **마지막에 도달한 노드의 클래스 비율을 보고 예측을 만든다.**
> 

### 🎋 가지치기

결정 트리에서는 **일반화**를 위해 **가지치기**를 해야 한다!

결정 트리는 제한 없이 성장하면 훈련 세트에 **과대적합**되기 쉽다. **가지치기**는 결정 트리의 성장을 제한하는 방법이다. 사이킷런의 결정 트리 알고리즘은 여러 가지 가지치기 매개변수를 제공한다. 

- 자라날 수 있는 트리의 최대 깊이를 지정 (`max_depth`)
- `min_impurity_decrease`를 사용
    - 어떤 노드의 정보 이득 x (노드의 샘플 수) / (전체 샘플 수) 값이 이 매개변수보다 작으면 더 이상 분할하지 않는다.
    
    → 좌우가 균일하지 않은 트리가 만들어진다. 
    

### 🌴 DecisionTreeClassifier

- `criterion` : 불순도 지정 (기본값 : `gini`, `entropy`도 사용 가능)
- `splitter` : 노드를 분할하는 전략
    - `best` : 기본값, 정보 이득이 최대가 되도록 분할
    - `random` : 임의로 노드를 분할
- `max_depth` : 트리가 성장할 최대 깊이 (기본값 : `None`, 리프 노드가 순수하거나 `min_samples_split`보다 샘플 개수가 적을 때까지 성장)
- `min_samples_split` : 노드를 나누기 위한 최소 샘플 개수 (기본값 : 2)
- `max_features` : 최적의 분할을 위해 탐색할 특성의 개수를 지정 (기본값 : `None`, 모든 특성을 사용)

- `plot_tree()` : 결정 트리 모델을 시각화
    - `max_depth` : 나타낼 트리의 깊이 지정
    - `feature_names` : 특성의 이름 지정
    - `filled` : `True`로 지정하면 타깃값에 따라 노드 안에 색을 채운다